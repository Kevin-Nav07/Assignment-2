{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "**Dataset Name:** Netflix Movies and TV Shows\n",
    "\n",
    "**Author:**  \n",
    "\n",
    "Shivam Bansal \n",
    "\n",
    "**Purpose:**  \n",
    "The dataset was created to provide a comprehensive overview of the content available on Netflix, including both movies and TV shows. It is intended for analyzing trends in streaming media, content diversity, and release patterns. Researchers, analysts, and data scientists can use this dataset to explore aspects such as user engagement, content curation, and recommendation systems\n",
    "\n",
    "**Shape:**  \n",
    "- **Rows:** 8807 \n",
    "- **Columns:** 12 \n",
    "\n",
    "**Features and Descriptions:**\n",
    "\n",
    "1. **show_id (Categorical):**  \n",
    "   A unique identifier for each show, represented as a string.\n",
    "\n",
    "2. **type (Categorical):**  \n",
    "   Indicates whether the entry is a 'Movie' or a 'TV Show'.\n",
    "\n",
    "3. **title (Categorical):**  \n",
    "   The title of the movie or TV show.\n",
    "\n",
    "4. **director (Categorical):**  \n",
    "   The name(s) of the director(s). This field may include multiple names separated by commas.\n",
    "\n",
    "5. **cast (Categorical):**  \n",
    "   The main cast members featured in the content. Multiple names may be present.\n",
    "\n",
    "6. **country (Categorical):**  \n",
    "   The country or countries where the content was produced.\n",
    "\n",
    "7. **date_added (Categorical/Date):**  \n",
    "   The date when the show was added to Netflix. Although stored as a string, it represents a date (typically in the format \"Month Day, Year\").\n",
    "\n",
    "8. **release_year (Numerical):**  \n",
    "   The year in which the content was originally released, represented as an integer.\n",
    "\n",
    "9. **rating (Categorical):**  \n",
    "   The content rating (e.g., PG, PG-13, R, TV-MA), which indicates the suitability of the content for different audiences.\n",
    "\n",
    "10. **duration (Categorical/Numerical):**  \n",
    "    For movies, this is usually a string indicating the duration in minutes (e.g., \"90 min\"). For TV shows, it is a string indicating the number of seasons (e.g., \"2 Seasons\").\n",
    "\n",
    "11. **listed_in (Categorical):**  \n",
    "    A list of genres or categories that the content belongs to, stored as a string with multiple categories separated by commas.\n",
    "\n",
    "12. **description (Categorical):**  \n",
    "    A brief summary or description of the content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 Range Check of Release Year\n",
    "**Range Check of Release Year** \n",
    "  This test checks whether the 'release_year' values fall within an acceptable range.\n",
    " For Netflix shows, we expect the release year to be between 1900 and the current year (e.g., 2025). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2005,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#initially loading the dataset for the rest of the file\n",
    "url = \"netflix_titles.csv\"\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2006,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Report\n",
    "# print(\"Range Check for 'release_year':\")\n",
    "# print(\"Found {} rows with a release year below {} or above {}.\".format(len(invalid_years), minimum, maximum))\n",
    "# if not invalid_years.empty:\n",
    "#     print(\"Here are some example of rows that exceed these thresholds:\")\n",
    "#     print(invalid_years[['show_id', 'title', test_attribute]].head())\n",
    "# else:\n",
    "#     print(\"All 'release_year' values are within range\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2 Data Type Errors Check\n",
    "This test verifies that the values in a specified column match the expected data type.\n",
    " For example, the 'release_year' should be an integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2007,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrs\n",
    "import re\n",
    "\n",
    "\n",
    "test_attribute = 'release_year'\n",
    "minimum = 1900\n",
    "maximum = 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid whole integer (only digits)\n",
    "def is_valid_year(value):\n",
    "    try:\n",
    "       \n",
    "        return str(value).strip().isdigit()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "year_type_errors = df[~df[test_attribute].apply(is_valid_year)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type Errors Check for 'release_year':\n",
      "Expected: each value should be a whole integer (only digits, no extra characters).\n",
      "Number of rows with type errors: 0\n",
      "All values in the 'release_year' column are valid whole integers.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Type Errors Check for '{test_attribute}':\")\n",
    "print(\"Expected: each value should be a whole integer (only digits, no extra characters).\")\n",
    "print(f\"Number of rows with type errors: {len(year_type_errors)}\")\n",
    "if not year_type_errors.empty:\n",
    "    print(\"Examples of rows with type errors:\")\n",
    "    print(year_type_errors[['show_id', test_attribute]].head())\n",
    "else:\n",
    "    print(f\"All values in the '{test_attribute}' column are valid whole integers.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Errors Check:\n",
    "This test verifies that the 'date_added' column follows the expected date format,\n",
    "e.g., \"Month Day, Year\" (such as \"September 09, 2019\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2010,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "test_attribute = 'date_added'\n",
    "expected_format = '%B %d, %Y'  # here is the expected format, \"September 09, 2019\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2011,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def check_date_format(date_str, fmt):\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_str.strip(), fmt)\n",
    "        return True\n",
    "    except (ValueError, AttributeError):\n",
    "        return False\n",
    "\n",
    "# Apply the format check to each value in the column of data added\n",
    "format_errors = df[~df[test_attribute].apply(lambda x: check_date_format(x, expected_format) if pd.notnull(x) else True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Errors Check for 'date_added' column:\n",
      "Expected format: %B %d, %Y\n",
      "Number of rows with formts deviating from that format0\n",
      "All rows in 'date_added' column follow the expected format.\n"
     ]
    }
   ],
   "source": [
    "#report\n",
    "print(\"Format Errors Check for '{}' column:\".format(test_attribute)) \n",
    "print(\"Expected format: {}\".format(expected_format))\n",
    "print(\"Number of rows with formts deviating from that format{}\".format(len(format_errors)))\n",
    "if not format_errors.empty:\n",
    "    print(\"Here are some example rows with format errors:\")\n",
    "    print(format_errors[['show_id', 'date_added']].head())\n",
    "else:\n",
    "    print(\"All rows in '{}' column follow the expected format.\".format(test_attribute))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniqueness Errors Check:\n",
    "This test checks that the 'show_id' column contains unique values,\n",
    "ensuring that each record in the dataset is uniquely identifiable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2013,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parmeters\n",
    "test_attr = 'show_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicate entries in the 'show_id' column to find lack of uniqueness\n",
    "duplicate_rows = df[df[test_attr].duplicated(keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqueness Errors Check for  'show_id':\n",
      "Found duplicate entries in 'date_added'. Each of these values should be unique. Below are all rows with duplicate values:\n",
      "  show_id     type                          title         director  \\\n",
      "1      s2  TV Show                  Blood & Water              NaN   \n",
      "3      s5  TV Show                   Kota Factory              NaN   \n",
      "4      s5  TV Show                   Kota Factory              NaN   \n",
      "8      s2  TV Show  The Great British Baking Show  Andy Devonshire   \n",
      "\n",
      "                                                cast         country  \\\n",
      "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...    South Africa   \n",
      "3  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...           India   \n",
      "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...           India   \n",
      "8  Mel Giedroyc, Sue Perkins, Mary Berry, Paul Ho...  United Kingdom   \n",
      "\n",
      "           date_added  release_year rating   duration  \\\n",
      "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "3  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "8  September 24, 2021          2021  TV-14  9 Seasons   \n",
      "\n",
      "                                           listed_in  \\\n",
      "1    International TV Shows, TV Dramas, TV Mysteries   \n",
      "3  International TV Shows, Romantic TV Shows, TV ...   \n",
      "4  International TV Shows, Romantic TV Shows, TV ...   \n",
      "8                       British TV Shows, Reality TV   \n",
      "\n",
      "                                         description  \n",
      "1  After crossing paths at a party, a Cape Town t...  \n",
      "3  In a city of coaching centers known to train I...  \n",
      "4  In a city of coaching centers known to train I...  \n",
      "8  A talented batch of amateur bakers face off in...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Uniqueness Errors Check for  '{}':\".format(test_attr))\n",
    "if duplicate_rows.empty:\n",
    "    print(\"All values in '{}' column are unique.\".format(test_attr))\n",
    "else:\n",
    "    print(\"Found duplicate entries in '{}'. Each of these values should be unique. Below are all rows with duplicate values:\".format(test_attribute))\n",
    "    print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Errors Check:\n",
    "Consistency Check between 'type' and 'duration':\n",
    "This test verifies that the duration field is consistent with the type of show.\n",
    "For a \"Movie\", the duration should include \"min\" (indicating minutes),\n",
    "while for a \"TV Show\", the duration should include \"Season\" (or \"Seasons\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "type_column = 'type'\n",
    "duration_column = 'duration'\n",
    "expected_for_movie = 'min'       \n",
    "expected_for_tv_show = 'season' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for movies, check if 'duration' doesn't contain \"min\" which includes minutes and for tv shows check durations doesn't contain season \n",
    "movie_inconsistencies = df[\n",
    "    (df[type_column].str.lower() == 'movie') &\n",
    "    (~df[duration_column].str.lower().str.contains(expected_for_movie, na=False))\n",
    "]\n",
    "\n",
    "tv_inconsistencies = df[\n",
    "    (df[type_column].str.lower() == 'tv show') &\n",
    "    (~df[duration_column].str.lower().str.contains(expected_for_tv_show, na=False))\n",
    "]\n",
    "\n",
    "consistency_errors = pd.concat([movie_inconsistencies, tv_inconsistencies])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency Check between 'type' and 'duration' to see if seasons and minutes are:\n",
      "For 'movie', duration should contain 'min'.\n",
      "For 'TV Show', duration should contain 'Season'.\n",
      "Here are the number of rows with consistency errors: 5\n",
      "examples of consistency errors in the dataset :\n",
      "         type  duration show_id                                 title\n",
      "0       Movie  6 season      s1                  Dick Johnson Is Dead\n",
      "5541    Movie       NaN   s5542                       Louis C.K. 2017\n",
      "5794    Movie       NaN   s5795                 Louis C.K.: Hilarious\n",
      "5813    Movie       NaN   s5814  Louis C.K.: Live at the Comedy Store\n",
      "14    TV Show  1 minute     s15       Crime Stories: India Detectives\n"
     ]
    }
   ],
   "source": [
    "print(\"Consistency Check between 'type' and 'duration' to see if seasons and minutes are:\")\n",
    "print(\"For 'movie', duration should contain '{}'.\".format(expected_for_movie))\n",
    "print(\"For 'TV Show', duration should contain '{}'.\".format(expected_for_tv_show.capitalize()))\n",
    "print(\"Here are the number of rows with consistency errors: {}\".format(len(consistency_errors)))\n",
    "if not consistency_errors.empty:\n",
    "    print(\"examples of consistency errors in the dataset :\")\n",
    "    print(consistency_errors[[type_column, duration_column, 'show_id', 'title']].head())\n",
    "else:\n",
    "    print(\"All rows are consistent between 'type' and 'duration'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presence Errors Check:\n",
    "This test verifies that there are no missing (null) values in a critical column.\n",
    "For example, every record should have a non-empty 'title'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_attribute = 'title'  # Change to any column that must always have a value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where the specified column is missing or null\n",
    "presence_errors = df[df[test_attribute].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2021,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Errors Check for column 'title':\n",
      "Found 1 rows with missing values in 'title'.\n",
      "Here are some examples of rows with missing values:\n",
      "   show_id title\n",
      "67     s68   NaN\n"
     ]
    }
   ],
   "source": [
    "print(f\"Presence Errors Check for column '{test_attribute}':\")\n",
    "print(f\"Found {len(presence_errors)} rows with missing values in '{test_attribute}'.\")\n",
    "if not presence_errors.empty:\n",
    "    print(\"Here are some examples of rows with missing values:\")\n",
    "    print(presence_errors[['show_id', test_attribute]].head())\n",
    "else:\n",
    "    print(f\"All rows in the '{test_attribute}' column are complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length Errors Check:\n",
    " This test verifies that the text in a specified column meets defined length constraints.\n",
    " For example, the 'description' field should have a minimum and maximum character count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2022,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_attribute = 'description'  \n",
    "min_length = 10    \n",
    "max_length = 500   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where the length of text is either exceeding the maximum or below the minimum\n",
    "length_errors = df[(df[test_attribute].str.len() < min_length) | (df[test_attribute].str.len() > max_length)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Errors Check for column 'description':\n",
      "Allowed length: minimum 10 characters, maximum 500 characters.\n",
      "Number of rows with length errors: 1\n",
      "Examples of rows with length errors:\n",
      "show_id description\n",
      "   s111   The film.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length Errors Check for column '{test_attribute}':\")\n",
    "print(f\"Allowed length: minimum {min_length} characters, maximum {max_length} characters.\")\n",
    "print(f\"Number of rows with length errors: {length_errors.shape[0]}\")\n",
    "\n",
    "if not length_errors.empty:\n",
    "    print(\"Examples of rows with length errors:\")\n",
    "    print(length_errors.loc[:, ['show_id', test_attribute]].head().to_string(index=False))\n",
    "else:\n",
    "    print(f\"All rows in '{test_attribute}' column fall within the allowed length range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look-up Errors Check:\n",
    "This test verifies that the values in a specified column exist within a predefined list (lookup table).\n",
    "For example, the 'rating' column should only contain values from an approved set of ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "test_attribute = 'rating'\n",
    "allowed_ratings = ['G', 'PG', 'PG-13', 'R', 'NC-17', 'TV-MA', 'TV-14', 'TV-PG','TV-Y', 'TV-Y7','TV-G', 'NR'] #this is adjustable as it might not cover every possible tv rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a check for each entry that is case-insensitive and iterate through the look-up table\n",
    "allowed = set([rating.upper() for rating in allowed_ratings])\n",
    "LookupError = df[~df[test_attribute].str.upper().isin(allowed)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-up Errors Check for column 'rating':\n",
      "Allowed ratings: G, PG, PG-13, R, NC-17, TV-MA, TV-14, TV-PG, TV-Y, TV-Y7, TV-G, NR\n",
      "Number of rows with values not in the allowed lookup list: 16\n",
      "Here are examples of rows with look-up errors:\n",
      "show_id   rating\n",
      "  s5542   74 min\n",
      "  s5795   84 min\n",
      "  s5814   66 min\n",
      "  s5990      NaN\n",
      "  s6582 TV-Y7-FV\n"
     ]
    }
   ],
   "source": [
    "print(f\"Look-up Errors Check for column '{test_attribute}':\")\n",
    "print(f\"Allowed ratings: {', '.join(map(str, allowed_ratings))}\")\n",
    "print(f\"Number of rows with values not in the allowed lookup list: {LookupError.shape[0]}\")\n",
    "\n",
    "if not LookupError.empty:\n",
    "    print(\"Here are examples of rows with look-up errors:\")\n",
    "    print(LookupError.loc[:, ['show_id', test_attribute]].head().to_string(index=False))\n",
    "else:\n",
    "    print(f\"All rows in '{test_attribute}' column match the allowed lookup values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact Duplicate Errors Check:\n",
    "This test identifies rows in the dataset that are exact duplicates across all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# No additional parameters are needed; this check considers all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all exact duplicate rows in the entire dataset\n",
    "exact_duplicates = df[df.duplicated(keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2030,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Duplicate Errors Check:\n",
      "Number of rows that are exact duplicates. The rows displayed will be truncated so that we only display a few of the columns so the output does not get messy. The entire row will be considered a duplicate though.: 2\n",
      "Here are examples of exact duplicate rows:\n",
      "  show_id         title\n",
      "3      s5  Kota Factory\n",
      "4      s5  Kota Factory\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Duplicate Errors Check:\")\n",
    "print(\"Number of rows that are exact duplicates. The rows displayed will be truncated so that we only display a few of the columns so the output does not get messy. The entire row will be considered a duplicate though.: {}\".format(len(exact_duplicates)))\n",
    "if not exact_duplicates.empty:\n",
    "    print(\"Here are examples of exact duplicate rows:\")\n",
    "    print(exact_duplicates[['show_id', 'title']].head())\n",
    "else:\n",
    "    print(\"No exact duplicate rows found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Near Duplicate Check using Sorted Titles Comparison:\n",
    "This test identifies near duplicates in the 'title' column by splitting each title into tokens,\n",
    "computing the Jaccard similarity between adjacent titles (after sorting),\n",
    "and flagging titles with a similarity above a defined threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2031,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "test_attribute = 'title'      \n",
    "similarity_threshold = 0.95   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2032,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Compute the Jaccard similarity between two strings based on word tokens.\n",
    "    \"\"\"\n",
    "    tokens_a = set(a.split())\n",
    "    tokens_b = set(b.split())\n",
    "    union = tokens_a.union(tokens_b)\n",
    "    if not union:\n",
    "        return 0\n",
    "    return len(tokens_a.intersection(tokens_b)) / len(union)\n",
    "\n",
    "#  convert to lower case and strip whitespace; pair each title with its original index then sort the list\n",
    "\n",
    "titles_data = [(idx, str(title).lower().strip()) for idx, title in df[test_attribute].fillna(\"\").items()]\n",
    "\n",
    "\n",
    "titles_sorted = sorted(titles_data, key=lambda x: x[1])\n",
    "\n",
    "\n",
    "near_duplicate_indices = set()\n",
    "\n",
    "# Compare each title with its immediate neighbor in the sorted list using Jaccard similarity and then then add it to the list of indices as flagged\n",
    "for i in range(len(titles_sorted) - 1):\n",
    "    idx1, title1 = titles_sorted[i]\n",
    "    idx2, title2 = titles_sorted[i + 1]\n",
    "    similarity = jaccard_similarity(title1, title2)\n",
    "    if similarity >= similarity_threshold:\n",
    "        near_duplicate_indices.add(idx1)\n",
    "        near_duplicate_indices.add(idx2)\n",
    "        \n",
    "\n",
    "near_duplicate_rows = df.loc[list(near_duplicate_indices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2033,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near Duplicate Check using Sorted Titles Comparison on column 'title':\n",
      "Similarity threshold: 0.95\n",
      "Number of rows that are flagged as near duplicates: 14\n",
      "Here are all the near duplicates\n",
      "     show_id                     title\n",
      "6529   s6530             Consequences \n",
      "3         s5              Kota Factory\n",
      "4         s5              Kota Factory\n",
      "5318   s5319                Death Note\n",
      "5095   s5096       Fullmetal Alchemist\n",
      "5033   s5034       FullMetal Alchemist\n",
      "3371   s3372              Consequences\n",
      "303     s304      Esperando la carroza\n",
      "6705   s6706      Esperando La Carroza\n",
      "7345   s7346            Love In A Puff\n",
      "1270   s1271  Sin senos sí hay paraíso\n",
      "5751   s5752                DEATH NOTE\n",
      "8022   s8023  Sin Senos sí Hay Paraíso\n",
      "159     s160            Love in a Puff\n"
     ]
    }
   ],
   "source": [
    "print(f\"Near Duplicate Check using Sorted Titles Comparison on column '{test_attribute}':\")\n",
    "print(f\"Similarity threshold: {similarity_threshold}\")\n",
    "print(f\"Number of rows that are flagged as near duplicates: {len(near_duplicate_rows)}\")\n",
    "if not near_duplicate_rows.empty:\n",
    "    print(\"Here are all the near duplicates\")\n",
    "    print(near_duplicate_rows[['show_id', test_attribute]])\n",
    "    \n",
    "else:\n",
    "    print(f\"No near duplicate rows found based on the '{test_attribute}' column.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
